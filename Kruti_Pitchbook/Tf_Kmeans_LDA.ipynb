{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08683181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your numpy version: 1.22.2 (need at least 1.7.1)\n",
      "Your SciPy version:  1.7.1 (need at least 0.12.0)\n",
      "Your Pandas version:  1.3.4 (need at least 0.11.0)\n",
      "Your Mapltolib version:  3.4.3 (need at least 1.2.1)\n",
      "Your Scikit-Learn version:  1.0.2 (need at least 0.13.1)\n"
     ]
    }
   ],
   "source": [
    "# Numpy is a library for working with Arrays\n",
    "import numpy as np\n",
    "print (\"Your numpy version: %6.6s (need at least 1.7.1)\" % np.__version__)\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print (\"Your SciPy version: %6.6s (need at least 0.12.0)\" % sp.__version__)\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print (\"Your Pandas version: %6.6s (need at least 0.11.0)\" % pd.__version__)\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib\n",
    "print (\"Your Mapltolib version: %6.6s (need at least 1.2.1)\" % matplotlib.__version__)\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print (\"Your Scikit-Learn version: %6.6s (need at least 0.13.1)\" % sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa80b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/Kruti/Pitchbook/data/sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0228092b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac228a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.full_desc != '[N/A]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee378eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>full_desc</th>\n",
       "      <th>generated_keywords</th>\n",
       "      <th>verticals</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adtelligence</td>\n",
       "      <td>Provider of an e-commerce optimization and cus...</td>\n",
       "      <td>['cyber intelligence', 'user retention', 'audi...</td>\n",
       "      <td>['TMT', 'AdTech', 'Big Data', 'Artificial Inte...</td>\n",
       "      <td>['Business/Productivity Software', 'Media and ...</td>\n",
       "      <td>['Information Technology', 'Business Products ...</td>\n",
       "      <td>['Software', 'Commercial Services']</td>\n",
       "      <td>['data parameters', 'offer optimization', 'off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mojo (Educational Software)</td>\n",
       "      <td>Developer of sports application designed to ma...</td>\n",
       "      <td>['rafting', 'coaching software', 'sports train...</td>\n",
       "      <td>['Mobile', 'EdTech', 'SaaS']</td>\n",
       "      <td>['Educational and Training Services (B2C)', 'E...</td>\n",
       "      <td>['Consumer Products and Services (B2C)', 'Info...</td>\n",
       "      <td>['Services (Non-Financial)', 'Software', 'Soft...</td>\n",
       "      <td>['sports and recreation', 'youth athletes', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Status Money</td>\n",
       "      <td>Developer of a banking application designed to...</td>\n",
       "      <td>['digital banking platform', 'financial health...</td>\n",
       "      <td>['Big Data', 'FinTech', 'Artificial Intelligen...</td>\n",
       "      <td>['Application Software', 'Other Financial Serv...</td>\n",
       "      <td>['Information Technology', 'Financial Services...</td>\n",
       "      <td>['Software', 'Other Financial Services', 'Soft...</td>\n",
       "      <td>['cashbacks', 'bitcoin rewards', 'financial se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  entity_name  \\\n",
       "0           0                 Adtelligence   \n",
       "1           1  Mojo (Educational Software)   \n",
       "2           2                 Status Money   \n",
       "\n",
       "                                           full_desc  \\\n",
       "0  Provider of an e-commerce optimization and cus...   \n",
       "1  Developer of sports application designed to ma...   \n",
       "2  Developer of a banking application designed to...   \n",
       "\n",
       "                                  generated_keywords  \\\n",
       "0  ['cyber intelligence', 'user retention', 'audi...   \n",
       "1  ['rafting', 'coaching software', 'sports train...   \n",
       "2  ['digital banking platform', 'financial health...   \n",
       "\n",
       "                                           verticals  \\\n",
       "0  ['TMT', 'AdTech', 'Big Data', 'Artificial Inte...   \n",
       "1                       ['Mobile', 'EdTech', 'SaaS']   \n",
       "2  ['Big Data', 'FinTech', 'Artificial Intelligen...   \n",
       "\n",
       "                                       industry_code  \\\n",
       "0  ['Business/Productivity Software', 'Media and ...   \n",
       "1  ['Educational and Training Services (B2C)', 'E...   \n",
       "2  ['Application Software', 'Other Financial Serv...   \n",
       "\n",
       "                                     industry_sector  \\\n",
       "0  ['Information Technology', 'Business Products ...   \n",
       "1  ['Consumer Products and Services (B2C)', 'Info...   \n",
       "2  ['Information Technology', 'Financial Services...   \n",
       "\n",
       "                                      industry_group  \\\n",
       "0                ['Software', 'Commercial Services']   \n",
       "1  ['Services (Non-Financial)', 'Software', 'Soft...   \n",
       "2  ['Software', 'Other Financial Services', 'Soft...   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['data parameters', 'offer optimization', 'off...  \n",
       "1  ['sports and recreation', 'youth athletes', 'p...  \n",
       "2  ['cashbacks', 'bitcoin rewards', 'financial se...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45deb7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9905, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56671ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = data.filter(['entity_name', 'generated_keywords'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471659aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = data.filter(['full_desc'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc71dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df_desc.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278cfac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_desc[97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318595b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6380/2619171634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data' is not defined"
     ]
    }
   ],
   "source": [
    "#df_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e37bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87e1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c70083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    if not text:\n",
    "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "        text = ''\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "962ea6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not super pythonic, no, not at all.\n",
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in df_desc.index:\n",
    "    #print(i)\n",
    "    allwords_stemmed = tokenize_and_stem(df_desc['full_desc'][i]) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(df_desc['full_desc'][i])\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22bd0067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5fbb1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414087"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totalvocab_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ef6d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dine', 'experi', 'the', 'compani', 'offer']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalvocab_stemmed[200:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba1f18b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dining', 'experience', 'the', 'company', 'offers']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalvocab_tokenized[200:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e023650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 414087 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print ('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f17d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f30649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kruti\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.4 s\n",
      "(9905, 484)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.99, max_features=200000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(df_desc['full_desc']) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a2efa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "244474f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'s\", \"'s applic\", \"'s platform\", \"'s platform offer\",\n",
       "       \"'s platform provid\", \"'s product\", \"'s product includ\",\n",
       "       \"'s servic\", \"'s servic includ\", \"'s softwar\", \"'s technolog\",\n",
       "       'access', 'accessori', 'account', 'achiev', 'acquisit', 'activ',\n",
       "       'addit', 'administr', 'advanc', 'advertis', 'advisori', 'afford',\n",
       "       'agenc', 'agricultur', 'air', 'allow', 'allow user', 'altern',\n",
       "       'analysi', 'analyt', 'analyz', 'ani', 'applic', 'applic design',\n",
       "       'area', 'artifici', 'artifici intellig', 'assess', 'asset',\n",
       "       'assist', 'autom', 'automot', 'avail', 'bank', 'base', 'benefit',\n",
       "       'better', 'beverag', 'book', 'brand', 'build', 'busi', 'buy',\n",
       "       'california', 'canada', 'capit', 'car', 'card', 'care', 'cater',\n",
       "       'center', 'chain', 'channel', 'chemic', 'china', 'clean', 'client',\n",
       "       'clinic', 'cloud', 'cloud-bas', 'collabor', 'collect', 'combin',\n",
       "       'commerci', 'communic', 'communiti', 'compani', \"compani 's\",\n",
       "       \"compani 's applic\", \"compani 's platform\", \"compani 's product\",\n",
       "       \"compani 's servic\", \"compani 's softwar\", \"compani 's technolog\",\n",
       "       'compani compani', 'compani develop', 'compani engag',\n",
       "       'compani focus', 'compani intend', 'compani manufactur',\n",
       "       'compani offer', 'compani oper', 'compani provid',\n",
       "       'compani special', 'competit', 'complet', 'complex', 'complianc',\n",
       "       'compon', 'comprehens', 'comput', 'condit', 'connect', 'consist',\n",
       "       'construct', 'consult', 'consult servic', 'consum', 'contain',\n",
       "       'content', 'contract', 'control', 'conveni', 'corpor', 'cost',\n",
       "       'cost-effect', 'cover', 'creat', 'creativ', 'credit', 'current',\n",
       "       'custom', 'data', 'decis', 'deliv', 'deliveri', 'design',\n",
       "       'design help', 'design manufactur', 'design offer',\n",
       "       'design provid', 'detect', 'develop', 'develop onlin', 'devic',\n",
       "       'diagnost', 'differ', 'digit', 'direct', 'diseas', 'distribut',\n",
       "       'distributor', 'document', 'drive', 'drug', 'e-commerc', 'easili',\n",
       "       'educ', 'effect', 'effici', 'electr', 'electron', 'emerg',\n",
       "       'employe', 'enabl', 'enabl busi', 'enabl client', 'enabl compani',\n",
       "       'enabl custom', 'enabl user', 'energi', 'engag', 'engin', 'enhanc',\n",
       "       'enjoy', 'ensur', 'enterpris', 'entertain', 'environ',\n",
       "       'environment', 'equip', 'estat', 'event', 'exchang', 'experi',\n",
       "       'expertis', 'explor', 'fabric', 'facil', 'facilit', 'famili',\n",
       "       'farm', 'featur', 'field', 'financ', 'financi', 'financi servic',\n",
       "       'firm', 'fit', 'flexibl', 'focus', 'food', 'form', 'fuel',\n",
       "       'function', 'fund', 'game', 'gas', 'general', 'generat', 'germani',\n",
       "       'global', 'good', 'govern', 'group', 'grow', 'growth', 'handl',\n",
       "       'health', 'healthcar', 'healthi', 'heat', 'help', 'help client',\n",
       "       'high', 'hold', 'home', 'hospit', 'hotel', 'hous', 'human',\n",
       "       'identifi', 'imag', 'implement', 'improv', 'includ', 'increas',\n",
       "       'independ', 'individu', 'industri', 'industri compani', 'inform',\n",
       "       'inform technolog', 'infrastructur', 'innov', 'insight', 'instal',\n",
       "       'institut', 'insur', 'integr', 'intellig', 'intend', 'intend help',\n",
       "       'intend offer', 'intend provid', 'intend serv', 'interact',\n",
       "       'intern', 'internet', 'invest', 'item', 'kingdom', 'larg', 'lead',\n",
       "       'learn', 'level', 'life', 'light', 'like', 'line', 'live', 'loan',\n",
       "       'local', 'locat', 'logist', 'machin', 'main', 'maintain',\n",
       "       'mainten', 'major', 'make', 'manag', 'manag servic',\n",
       "       'manag softwar', 'manufactur', 'market', 'market compani',\n",
       "       'market servic', 'marketplac', 'materi', 'measur', 'mechan',\n",
       "       'media', 'medic', 'medicin', 'meet', 'metal', 'mobil',\n",
       "       'mobil applic', 'model', 'money', 'monitor', 'multipl', 'natur',\n",
       "       'need', 'network', 'new', 'offer', 'offer servic', 'offic', 'oil',\n",
       "       'oil gas', 'onlin', 'oper', 'oper onlin', 'opportun', 'optim',\n",
       "       'option', 'order', 'organ', 'owner', 'owner oper', 'packag',\n",
       "       'patient', 'payment', 'peopl', 'perform', 'person', 'pharmaceut',\n",
       "       'place', 'plan', 'plant', 'plastic', 'platform', 'platform design',\n",
       "       'platform intend', 'platform offer', 'platform provid',\n",
       "       'portfolio', 'power', 'practic', 'prevent', 'price', 'primarili',\n",
       "       'print', 'privat', 'process', 'produc', 'product',\n",
       "       'product compani', 'product includ', 'product intend',\n",
       "       'product servic', 'profession', 'program', 'project', 'promot',\n",
       "       'properti', 'protect', 'provid', 'provid custom', 'provid onlin',\n",
       "       'provid servic', 'public', 'publish', 'purchas', 'qualiti', 'rang',\n",
       "       'rate', 'real', 'real estat', 'real-tim', 'receiv', 'record',\n",
       "       'reduc', 'region', 'relat', 'relat product', 'relat servic',\n",
       "       'reliabl', 'rental', 'repair', 'report', 'requir', 'research',\n",
       "       'residenti', 'resourc', 'restaur', 'retail', 'revenu', 'right',\n",
       "       'risk', 'safe', 'safeti', 'sale', 'save', 'school', 'search',\n",
       "       'sector', 'sector compani', 'secur', 'segment', 'select', 'sell',\n",
       "       'serv', 'servic', 'servic base', 'servic compani',\n",
       "       \"servic compani 's\", 'servic compani offer',\n",
       "       'servic compani provid', 'servic enabl', 'servic includ',\n",
       "       'servic intend', 'servic offer', 'servic provid', 'set', 'share',\n",
       "       'shop', 'simplifi', 'singl', 'site', 'skill', 'small', 'smart',\n",
       "       'social', 'softwar', 'softwar design', 'solut', 'sourc', 'space',\n",
       "       'special', 'specialti', 'specif', 'sport', 'state', 'steel',\n",
       "       'storag', 'store', 'strategi', 'structur', 'student', 'suit',\n",
       "       'suppli', 'supplier', 'support', 'sustain', 'target', 'team',\n",
       "       'technic', 'technolog', 'telecommun', 'test', 'therapi', 'therebi',\n",
       "       'therebi enabl', 'therebi help', 'time', 'tool', 'track', 'trade',\n",
       "       'train', 'transform', 'transport', 'travel', 'treat', 'treatment',\n",
       "       'truck', 'type', 'uniqu', 'unit', 'unit kingdom', 'unit state',\n",
       "       'use', 'user', 'util', 'valu', 'varieti', 'various', 'vehicl',\n",
       "       'video', 'virtual', 'visual', 'wast', 'water', 'way', 'web',\n",
       "       'websit', 'wide', 'wide rang', 'women', 'work', 'world'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a00b9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31644df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 15\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "%time km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629a1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sklearn.externals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef4d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "#joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e2faf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pd.DataFrame(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b91d9cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   7\n",
       "1  10\n",
       "2  10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1e1cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(index = [clusters], columns = [df_name, cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8276d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pd.merge(df_name, cluster, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c2c5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.rename(columns = {0: \"Cluster\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25cf9edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>generated_keywords</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adtelligence</td>\n",
       "      <td>['cyber intelligence', 'user retention', 'audi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mojo (Educational Software)</td>\n",
       "      <td>['rafting', 'coaching software', 'sports train...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Status Money</td>\n",
       "      <td>['digital banking platform', 'financial health...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coya Restaurant</td>\n",
       "      <td>['beverage products', 'cloud kitchen platform'...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trista</td>\n",
       "      <td>['publishing services firm', 'publishing servi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entity_name  \\\n",
       "0                 Adtelligence   \n",
       "1  Mojo (Educational Software)   \n",
       "2                 Status Money   \n",
       "3              Coya Restaurant   \n",
       "4                       Trista   \n",
       "\n",
       "                                  generated_keywords  Cluster  \n",
       "0  ['cyber intelligence', 'user retention', 'audi...        7  \n",
       "1  ['rafting', 'coaching software', 'sports train...       10  \n",
       "2  ['digital banking platform', 'financial health...       10  \n",
       "3  ['beverage products', 'cloud kitchen platform'...       11  \n",
       "4  ['publishing services firm', 'publishing servi...        7  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cf29d38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14    2009\n",
       "7     1404\n",
       "2     1042\n",
       "0      825\n",
       "8      790\n",
       "11     646\n",
       "9      529\n",
       "5      500\n",
       "13     479\n",
       "4      448\n",
       "12     368\n",
       "10     295\n",
       "3      189\n",
       "6      187\n",
       "1      100\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames['Cluster'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acab2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'product'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6380/1950562464.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0morder_centroids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#replace 6 with n words per cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvocab_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add whitespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add whitespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1557\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m         \u001b[1;31m# a single integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \"\"\"\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m             \u001b[1;31m# re-raise with different error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3626\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m         \"\"\"\n\u001b[1;32m-> 3628\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3629\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3613\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3615\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3616\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3617\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m         )\n\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'product'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        print(' %s' % vocab_frame.iloc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "    print(\"Cluster %d titles:\" % i, end='')\n",
    "    for title in frames.ix[i]['entity_name'].values.tolist():\n",
    "        print(' %s,' % title, end='')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
